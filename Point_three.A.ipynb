{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL DEDICATED TO IMPORT PACKAGES USEFUL FOR OUR PURPOSES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Conv2D,Flatten,Dropout, MaxPooling2D,AveragePooling2D\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time \n",
    "\n",
    "import import_ipynb\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME IMPORTANT GLOBAL VARIABLE\n",
    "labels = [\"Bedroom\",\"Coast\",\"Forest\",\"HighWay\",\"Industrial\",\"InsideCity\",\"Kitchen\",\"LivingRoom\",\"Mountain\",\"Office\",\"OpenCountry\",\"Store\",\"Street\",\"Suburb\",\"TallBuilding\"]\n",
    "train_dir = '../images/train/'\n",
    "test_dir = '../images/test/'\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION OF TRAINING DATA\n",
    "\n",
    "In a similar way to the previous parts, I preprocess my data; this time I have to take into account that images have to be suitable for VGG, so for example images will be of (224,224).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Fit data to make them suitable'''\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = utils.list_of_path(labels,train_dir)\n",
    "train_data,train_labels = utils.read_and_process_images(list_of_images,dimension=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_images =  []\n",
    "for im in list_of_images:\n",
    "    temp_img=image.load_img(im,target_size=(224,224))\n",
    "    temp_img=image.img_to_array(temp_img)\n",
    "    train_images.append(temp_img)\n",
    "\n",
    "    \n",
    "\n",
    "train_images=np.array(train_images)\n",
    "train_img=(train_images)\n",
    "\n",
    "\n",
    "train_labels = le.fit_transform(train_labels)\n",
    "train_labels_dummy=to_categorical(train_labels,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION OF TEST DATA\n",
    "\n",
    "Same thing with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = utils.list_of_path(labels,test_dir)\n",
    "test_data,test_labels = utils.read_and_process_images(list_of_images,dimension=224)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "test_images =  []\n",
    "\n",
    "for im in list_of_images:\n",
    "    temp_img=image.load_img(im,target_size=(224,224))\n",
    "    temp_img=image.img_to_array(temp_img)\n",
    "    test_images.append(temp_img)\n",
    "\n",
    "    \n",
    "test_images=np.array(test_images)\n",
    "test_img=preprocess_input(test_images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_labels=le.fit_transform(test_labels)\n",
    "test_labelsdummy=to_categorical(test_labels,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model(img_rows, img_cols, channel=1, num_classes=15):\n",
    "    \"\"\"\n",
    "    Function which initialize a model which is equal to the vgg_16, with the last classification\n",
    "    layer adapted for our problem (15 classification layer)\n",
    "    \n",
    "    Input img_rows = x dimension of images\n",
    "    Input img_cols = y dimension of images\n",
    "    Input channel(1)= number of channels of the images\n",
    "    Input num_classes(15) = number of classes to classify\n",
    "    \n",
    "    Output model_res =  VGG16 model\n",
    "    \"\"\"\n",
    "    adam = optimizers.Adam()\n",
    "    model = VGG16(weights='imagenet', include_top=True)\n",
    "    model_res = Sequential()\n",
    "    for layer in model.layers[:-1]: # just exclude last layer from copying\n",
    "        model_res.add(layer)\n",
    "    \n",
    "    model_res.add(Dense(15,activation='softmax'))\n",
    "    for layer in model_res.layers[:-1]:\n",
    "\n",
    "        layer.trainable = False\n",
    "    model_res.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16_model(224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "print(\"My Custom CNN Network:\")\n",
    "plot_model(model, to_file='Images_point_three/model_tl.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Training the model'''\n",
    "history = History()\n",
    "earlyStopping = EarlyStopping(min_delta=0.00,patience = 3)\n",
    "start_time_1 = time.time()\n",
    "model.fit(train_img,train_labels_dummy,batch_size=64,epochs=10,validation_split=0.15,shuffle=True,callbacks=[earlyStopping,history])\n",
    "end_time_1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_svv = utils.convert(end_time_1-start_time_1)\n",
    "timing_svv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Evaluating the model'''\n",
    "eval_time_start = time.time()\n",
    "ev = model.evaluate(test_img,test_labelsdummy)\n",
    "eval_time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim = utils.convert(eval_time_end - eval_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''I predict classes of my test_data in order to build my confusion matrix''' \n",
    "y_pred = model.predict_classes(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,7)) \n",
    "utils.plot_confusion_matrix(cm,labels,\"point_three\",\"images_point_three/\",normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"validation loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"val-loss\")\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.grid()\n",
    "plt.savefig(\"images_point_three/validation_loss_3.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"validation accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.grid()\n",
    "plt.savefig(\"images_point_three/validation_accuracy_3.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\" accuracy\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.grid()\n",
    "plt.savefig(\"images_point_three/accuracy_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(history.history['loss'])\n",
    "plt.grid()\n",
    "plt.savefig(\"images_point_three/loss_3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
