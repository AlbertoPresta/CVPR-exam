{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING\n",
    "\n",
    "So far I achieved a test accuracy of about  65-66%, using only shallow network that I developed from scratch using keras.\n",
    "\n",
    "Now, The aim of this framework is to exploit pre-trained network (such as GVV or alexnet) and apply the so called \"transfer learning\".\n",
    "\n",
    "In the first part, I simply freeze all the weights of the network, but the last one dense layer and I train only the last weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CELL DEDICATED TO IMPORT PACKAGES USEFULL FOR OUR PURPOSES\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import History\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils import plot_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.layers import Conv2D,Flatten,Dropout, MaxPooling2D,AveragePooling2D\n",
    "\n",
    "import import_ipynb\n",
    "import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG \n",
    "\n",
    "The first pre-trained network that I will exploit is the VGG\n",
    "\n",
    "### PROBLEM OF DATA\n",
    "\n",
    "The first problem is that pre-trained cnn are yet trained, in particulare they are all trained for working with coloured images...but our data-set is formed by b&w images! How can I do? my simple idea is to copy the first Chanel values to other two channel and create a 3 channel image out of your gray scale image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOME IMPORTANT GLOBAL VARIABLE\n",
    "labels = [\"Bedroom\",\"Coast\",\"Forest\",\"HighWay\",\"Industrial\",\"InsideCity\",\"Kitchen\",\"LivingRoom\",\"Mountain\",\"Office\",\"OpenCountry\",\"Store\",\"Street\",\"Suburb\",\"TallBuilding\"]\n",
    "train_dir = '../images/train/'\n",
    "test_dir = '../images/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of  initial data\n",
    "#train data\n",
    "list_of_images = utils.list_of_path(labels,train_dir)\n",
    "train_data,train_labels= utils.read_and_process_images(list_of_images)\n",
    "\n",
    "#test data\n",
    "list_of_images_test = utils.list_of_path(labels,test_dir)\n",
    "test_data,test_labels = utils.read_and_process_images(list_of_images_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 64, 64)\n",
      "(1500, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)  # (64, 224, 224)\n",
    "rgb_batch = np.repeat(train_data[..., np.newaxis], 3, -1)\n",
    "print(rgb_batch.shape)  # (64, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      " 10330112/553467096 [..............................] - ETA: 51:07"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
