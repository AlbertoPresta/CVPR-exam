{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST ATTEMPT TO CNN\n",
    "\n",
    "In this framework, I will try to built a first attempt to the neural networ requested by the project, so I try to answer to the first part of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "from keras.utils import to_categorical #to create dummy variable\n",
    "from keras.layers import Conv2D,Flatten,Dropout, MaxPooling2D,AveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING DEI  DATI \n",
    "\n",
    "The most popular and de facto standard library in Python for loading and working with image data is Pillow. Pillow is an updated version of the Python Image Library, or PIL, and supports a range of simple and sophisticated image manipulation functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(276, 200)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "image = Image.open('../images/test/Bedroom/image_0003.jpg')\n",
    "print(image.size)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '../images/'\n",
    "train_dir=os.path.join(base_dir,'train')\n",
    "test_dir=os.path.join(base_dir,'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = '../images/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Bedroom\",\"Coast\",\"Forest\",\"HighWay\",\"Industrial\",\"InsideCity\",\"Kitchen\",\"LivingRoom\",\"Mountain\",\"Office\",\"OpenCountry\",\"Store\",\"Street\",\"Suburb\",\"TallBuilding\"]\n",
    "forest = '../images/train/Forest/'\n",
    "bedroom = '../images/train/Bedroom/'\n",
    "#this represents all the directories for the different categories\n",
    "list_categories = ['../images/train/{}'.format(i) for i in os.listdir(train_dir) if i!='.DS_Store']\n",
    "bedroom_images = ['../images/train/Bedroom/{}'.format(i) for i in os.listdir(bedroom)]\n",
    "coast_images = ['../images/train/Coast/{}'.format(i) for i in os.listdir(train_dir+'/Coast/')]\n",
    "forest_images = ['../images/train/Forest/{}'.format(i) for i in os.listdir(forest)]\n",
    "Highway_images = [direc+'Highway/{}'.format(i) for i in os.listdir(train_dir+'/Highway/')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../images/train/Highway/image_0152.jpg',\n",
       " '../images/train/Highway/image_0224.jpg',\n",
       " '../images/train/Highway/image_0033.jpg',\n",
       " '../images/train/Highway/image_0219.jpg',\n",
       " '../images/train/Highway/image_0179.jpg',\n",
       " '../images/train/Highway/image_0151.jpg',\n",
       " '../images/train/Highway/image_0145.jpg',\n",
       " '../images/train/Highway/image_0186.jpg',\n",
       " '../images/train/Highway/image_0227.jpg',\n",
       " '../images/train/Highway/image_0019.jpg',\n",
       " '../images/train/Highway/image_0018.jpg',\n",
       " '../images/train/Highway/image_0187.jpg',\n",
       " '../images/train/Highway/image_0193.jpg',\n",
       " '../images/train/Highway/image_0154.jpg',\n",
       " '../images/train/Highway/image_0183.jpg',\n",
       " '../images/train/Highway/image_0222.jpg',\n",
       " '../images/train/Highway/image_0009.jpg',\n",
       " '../images/train/Highway/image_0021.jpg',\n",
       " '../images/train/Highway/image_0237.jpg',\n",
       " '../images/train/Highway/image_0223.jpg',\n",
       " '../images/train/Highway/image_0182.jpg',\n",
       " '../images/train/Highway/image_0169.jpg',\n",
       " '../images/train/Highway/image_0143.jpg',\n",
       " '../images/train/Highway/image_0209.jpg',\n",
       " '../images/train/Highway/image_0037.jpg',\n",
       " '../images/train/Highway/image_0023.jpg',\n",
       " '../images/train/Highway/image_0181.jpg',\n",
       " '../images/train/Highway/image_0050.jpg',\n",
       " '../images/train/Highway/image_0130.jpg',\n",
       " '../images/train/Highway/image_0118.jpg',\n",
       " '../images/train/Highway/image_0132.jpg',\n",
       " '../images/train/Highway/image_0126.jpg',\n",
       " '../images/train/Highway/image_0047.jpg',\n",
       " '../images/train/Highway/image_0127.jpg',\n",
       " '../images/train/Highway/image_0043.jpg',\n",
       " '../images/train/Highway/image_0094.jpg',\n",
       " '../images/train/Highway/image_0081.jpg',\n",
       " '../images/train/Highway/image_0254.jpg',\n",
       " '../images/train/Highway/image_0122.jpg',\n",
       " '../images/train/Highway/image_0120.jpg',\n",
       " '../images/train/Highway/image_0134.jpg',\n",
       " '../images/train/Highway/image_0256.jpg',\n",
       " '../images/train/Highway/image_0242.jpg',\n",
       " '../images/train/Highway/image_0054.jpg',\n",
       " '../images/train/Highway/image_0097.jpg',\n",
       " '../images/train/Highway/image_0083.jpg',\n",
       " '../images/train/Highway/image_0069.jpg',\n",
       " '../images/train/Highway/image_0055.jpg',\n",
       " '../images/train/Highway/image_0243.jpg',\n",
       " '../images/train/Highway/image_0138.jpg',\n",
       " '../images/train/Highway/image_0058.jpg',\n",
       " '../images/train/Highway/image_0064.jpg',\n",
       " '../images/train/Highway/image_0065.jpg',\n",
       " '../images/train/Highway/image_0059.jpg',\n",
       " '../images/train/Highway/image_0111.jpg',\n",
       " '../images/train/Highway/image_0113.jpg',\n",
       " '../images/train/Highway/image_0107.jpg',\n",
       " '../images/train/Highway/image_0073.jpg',\n",
       " '../images/train/Highway/image_0098.jpg',\n",
       " '../images/train/Highway/image_0072.jpg',\n",
       " '../images/train/Highway/image_0066.jpg',\n",
       " '../images/train/Highway/image_0258.jpg',\n",
       " '../images/train/Highway/image_0106.jpg',\n",
       " '../images/train/Highway/image_0112.jpg',\n",
       " '../images/train/Highway/image_0102.jpg',\n",
       " '../images/train/Highway/image_0248.jpg',\n",
       " '../images/train/Highway/image_0076.jpg',\n",
       " '../images/train/Highway/image_0077.jpg',\n",
       " '../images/train/Highway/image_0103.jpg',\n",
       " '../images/train/Highway/image_0117.jpg',\n",
       " '../images/train/Highway/image_0115.jpg',\n",
       " '../images/train/Highway/image_0129.jpg',\n",
       " '../images/train/Highway/image_0049.jpg',\n",
       " '../images/train/Highway/image_0128.jpg',\n",
       " '../images/train/Highway/image_0114.jpg',\n",
       " '../images/train/Highway/image_0167.jpg',\n",
       " '../images/train/Highway/image_0198.jpg',\n",
       " '../images/train/Highway/image_0239.jpg',\n",
       " '../images/train/Highway/image_0012.jpg',\n",
       " '../images/train/Highway/image_0204.jpg',\n",
       " '../images/train/Highway/image_0238.jpg',\n",
       " '../images/train/Highway/image_0199.jpg',\n",
       " '../images/train/Highway/image_0166.jpg',\n",
       " '../images/train/Highway/image_0170.jpg',\n",
       " '../images/train/Highway/image_0038.jpg',\n",
       " '../images/train/Highway/image_0010.jpg',\n",
       " '../images/train/Highway/image_0207.jpg',\n",
       " '../images/train/Highway/image_0165.jpg',\n",
       " '../images/train/Highway/image_0159.jpg',\n",
       " '../images/train/Highway/image_0175.jpg',\n",
       " '../images/train/Highway/image_0217.jpg',\n",
       " '../images/train/Highway/image_0028.jpg',\n",
       " '../images/train/Highway/image_0202.jpg',\n",
       " '../images/train/Highway/image_0148.jpg',\n",
       " '../images/train/Highway/image_0160.jpg',\n",
       " '../images/train/Highway/image_0189.jpg',\n",
       " '../images/train/Highway/image_0228.jpg',\n",
       " '../images/train/Highway/image_0016.jpg',\n",
       " '../images/train/Highway/image_0188.jpg',\n",
       " '../images/train/Highway/image_0163.jpg']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Highway_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = forest_images + bedroom_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = utils.read_and_process_images(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#first convolutional layer\n",
    "model.add(Conv2D(filters=8,kernel_size=3,padding='same',activation='relu',input_shape=(64,64,1)))\n",
    "model.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#secondo convolutional layer\n",
    "model.add(Conv2D(filters=16,kernel_size=3,strides=2,padding='same',activation='relu',input_shape=(64,64,1)))\n",
    "model.add(MaxPooling2D(pool_size=2,strides=2))\n",
    "#third convolutional layer\n",
    "model.add(Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=(64,64,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "#classification output\n",
    "model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
